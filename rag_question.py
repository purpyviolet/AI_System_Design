from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.vectorstores import FAISS
from langchain.embeddings import HuggingFaceEmbeddings

# åµŒå…¥æ¨¡å‹ï¼ˆä¿æŒä¸å˜ï¼‰
embedding = HuggingFaceEmbeddings(model_name="C:/Users/ZOE/Desktop/text2vec-base-chinese")

# åŠ è½½å‘é‡æ•°æ®åº“ï¼ˆç¡®ä¿è·¯å¾„æ­£ç¡®ï¼‰
db = FAISS.load_local(
    "faiss_oral_db", 
    embedding, 
    allow_dangerous_deserialization=True  # å…è®¸ååºåˆ—åŒ–
)

# æ„å»ºæ£€ç´¢å™¨
retriever = db.as_retriever(search_kwargs={"k": 1})

# é…ç½®ç¬¬ä¸‰æ–¹ä»£ç†è®¿é—® GPT-4
llm = ChatOpenAI(
    model_name="deepseek-chat",  # ç¡®ä¿ä»£ç†æ”¯æŒ GPT-4
    temperature=0.7,
    openai_api_key="sk-c317348a89df4b4faa79adaff8d688e2",  # æ›¿æ¢ä¸ºä½ çš„ä»£ç† API Key
    openai_api_base="https://api.deepseek.com/v1"  # æ›¿æ¢ä¸ºä»£ç†åœ°å€ï¼Œå¦‚ OneAPI
)

# æ„å»º QA é—®ç­”é“¾
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,  # ä½¿ç”¨é…ç½®å¥½çš„ LLM
    retriever=retriever,
    return_source_documents=True
)

# ç¤ºä¾‹é—®ç­”
query = "ç‰™ç»“çŸ³æ˜¯æ€ä¹ˆå½¢æˆçš„ï¼Ÿæ€ä¹ˆæ²»ç–—ï¼Ÿ"
result = qa_chain({"query": query})

print("ğŸ’¬ å›ç­”ï¼š", result["result"])
print("ğŸ“š å‚è€ƒæ¥æºï¼š", [doc.metadata for doc in result["source_documents"]])